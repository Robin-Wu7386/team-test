import pandas as pd
import json
import os
import random
import time
from typing import List, Dict
from datetime import datetime, timedelta
from pathlib import Path  # æ ¸å¿ƒï¼šç”¨pathlibå¤„ç†è·¯å¾„ï¼Œé€‚é…tuijian-endç›®å½•


# ===================== æ•°æ®å¤„ç†æ ¸å¿ƒå‡½æ•°ï¼ˆæ— æ”¹åŠ¨ï¼‰ =====================
def load_excel_data(excel_path: str) -> pd.DataFrame:
    if not os.path.exists(excel_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°Excelæ–‡ä»¶ï¼š{excel_path}")
    try:
        df = pd.read_excel(excel_path, engine='openpyxl')
        print(f"âœ… è¯»å–Excelï¼š{len(df)}è¡Œæ•°æ®")
        return df
    except ImportError:
        raise ImportError("è¯·å®‰è£…openpyxlï¼špip install openpyxl")
    except Exception as e:
        raise Exception(f"è¯»å–Excelå¤±è´¥ï¼š{str(e)}")


def clean_duplicate_data(df: pd.DataFrame, max_count: int = 10) -> pd.DataFrame:
    core_fields = ['è¯æID', 'è¯æåç§°', 'åˆ«å', 'æ€§å‘³', 'å½’ç»', 'åŠŸèƒ½ä¸»æ²»', 'ç”¨æ³•ç”¨é‡', 'ç”Ÿå¢ƒåˆ†å¸ƒ', 'æ³¨æ„']
    missing_fields = [f for f in core_fields if f not in df.columns]
    if missing_fields:
        print(f"âš ï¸  å¡«å……ç¼ºå¤±å­—æ®µï¼š{missing_fields}")
        for field in missing_fields:
            df[field] = 'æš‚æ— æ•°æ®'
    df_unique = df.drop_duplicates(subset=['è¯æID', 'è¯æåç§°'], keep='first').reset_index(drop=True)
    df_core = df_unique[core_fields].copy()
    for col in core_fields:
        df_core[col] = df_core[col].fillna('æš‚æ— æ•°æ®').astype(str)
    total_count = len(df_core)
    if total_count > max_count:
        random.seed(random.randint(1, 1000))  # æ¯æ¬¡éšæœºç§å­ä¸åŒï¼ŒæŠ½å–ä¸åŒæ•°æ®
        sample_index = random.sample(range(total_count), max_count)
        df_core = df_core.iloc[sample_index].reset_index(drop=True)
        print(f"âœ… éšæœºæŠ½å–{max_count}æ¡æ•°æ®")
    else:
        print(f"âœ… å»é‡åå‰©ä½™{len(df_core)}æ¡")
    return df_core


def classify_herb(function: str) -> tuple[str, str]:
    function = function.lower()
    if any(k in function for k in ['è¡¥æ°”', 'ç›Šæ°”']):
        return 'è¡¥æ°”', 'qi'
    elif any(k in function for k in ['è¡¥è¡€', 'å…»è¡€']):
        return 'è¡¥è¡€', 'xue'
    elif any(k in function for k in ['æ»‹é˜´', 'å…»é˜´']):
        return 'æ»‹é˜´', 'yin'
    elif any(k in function for k in ['è¡¥é˜³', 'æ¸©è‚¾']):
        return 'è¡¥é˜³', 'yang'
    elif any(k in function for k in ['æ¸…çƒ­', 'è§£æ¯’']):
        return 'æ¸…çƒ­', 'qingre'
    elif any(k in function for k in ['ç¥›æ¹¿', 'åˆ©æ°´']):
        return 'ç¥›æ¹¿', 'qushi'
    else:
        return 'å…¶ä»–', 'other'


def extract_tags(function: str) -> List[str]:
    tag_keywords = {'è¡¥æ°”': 'è¡¥æ°”', 'è¡¥è¡€': 'è¡¥è¡€', 'æ»‹é˜´': 'æ»‹é˜´', 'è¡¥é˜³': 'è¡¥é˜³', 'æ¸…çƒ­': 'æ¸…çƒ­', 'ç¥›æ¹¿': 'ç¥›æ¹¿'}
    tags = [v for k, v in tag_keywords.items() if k in function]
    return tags if tags else ['å…¶ä»–']


def extract_benefits(function: str) -> List[str]:
    if function == 'æš‚æ— æ•°æ®':
        return ['æš‚æ— åŠŸæ•ˆ']
    separators = ['ã€‚', 'ï¼›', 'ï¼Œ']
    benefits = [function.strip()]
    for sep in separators:
        temp = []
        for b in benefits:
            temp.extend([x.strip() for x in b.split(sep) if x.strip() and len(x.strip()) > 2])
        benefits = temp
    return list(set(benefits))[:3] if benefits else ['æš‚æ— åŠŸæ•ˆ']


def format_usage(usage: str) -> str:
    if usage == 'æš‚æ— æ•°æ®':
        return 'æš‚æ— ç”¨æ³•'
    if 'å†…æœ' not in usage and 'å¤–ç”¨' not in usage:
        return f'å†…æœï¼š{usage}'
    return usage


def generate_herb_info(df_core: pd.DataFrame) -> Dict:
    print("ğŸš€ å¤„ç†è¯ææ•°æ®...")
    df_core[['category', 'categoryId']] = df_core.apply(lambda x: pd.Series(classify_herb(x['åŠŸèƒ½ä¸»æ²»'])), axis=1)
    df_core['shortTags'] = df_core.apply(lambda x: extract_tags(x['åŠŸèƒ½ä¸»æ²»']), axis=1)
    df_core['benefits'] = df_core.apply(lambda x: extract_benefits(x['åŠŸèƒ½ä¸»æ²»']), axis=1)
    df_core['usage'] = df_core.apply(lambda x: format_usage(x['ç”¨æ³•ç”¨é‡']), axis=1)
    # å…³é”®ï¼šå›¾ç‰‡è·¯å¾„é€‚é…å‰ç«¯public/picturesç›®å½•ï¼ˆå»æ‰staticï¼Œç›´æ¥æŒ‡å‘publicï¼‰
    df_core['image'] = '/pictures/' + df_core['è¯æID'] + '_1.jpg'
    df_core['brief'] = df_core['åŠŸèƒ½ä¸»æ²»'].apply(lambda x: x[:50] + '...' if len(x) > 50 else x)

    complete_herb_list = []
    for idx, row in df_core.iterrows():
        herb_info = {
            "id": idx + 1,
            "name": row['è¯æåç§°'],
            "herbId": row['è¯æID'],
            "image": row['image'],
            "category": row['category'],
            "categoryId": row['categoryId'],
            "alias": row['åˆ«å'],
            "xingwei": row['æ€§å‘³'],
            "guijing": row['å½’ç»'],
            "brief": row['brief'],
            "shortTags": row['shortTags'],
            "tags": list(set([row['category']] + row['shortTags'])),
            "benefits": row['benefits'],
            "usage": row['usage'],
            "habitat": row['ç”Ÿå¢ƒåˆ†å¸ƒ'],
            "warning": row['æ³¨æ„'],
            "updateTime": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        complete_herb_list.append(herb_info)

    # éšæœºé€‰ç„¦ç‚¹è¯æ
    focus_herb = random.choice(complete_herb_list)

    # åˆ†ç±»é…ç½®
    categories = [
        {"id": "all", "name": "å…¨éƒ¨"}, {"id": "qi", "name": "è¡¥æ°”"}, {"id": "xue", "name": "è¡¥è¡€"},
        {"id": "yin", "name": "æ»‹é˜´"}, {"id": "yang", "name": "è¡¥é˜³"}, {"id": "qingre", "name": "æ¸…çƒ­"},
        {"id": "qushi", "name": "ç¥›æ¹¿"}, {"id": "other", "name": "å…¶ä»–"}
    ]
    category_stats = {"all": len(complete_herb_list)}
    for herb in complete_herb_list:
        cat_id = herb['categoryId']
        category_stats[cat_id] = category_stats.get(cat_id, 0) + 1
    categories_with_count = [{**cat, "count": category_stats.get(cat["id"], 0)} for cat in categories]

    return {
        "focusHerb": focus_herb,
        "herbList": complete_herb_list,
        "categories": categories_with_count,
        "categoryStats": category_stats,
        "totalCount": len(complete_herb_list),
        "globalUpdateTime": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }


def save_to_json(data: Dict, output_path: str) -> None:
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼ˆå¦‚æœviewsç›®å½•ä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»ºï¼‰
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            f.flush()  # å¼ºåˆ¶å†™å…¥ç£ç›˜ï¼Œé¿å…ç¼“å­˜
        # éªŒè¯æ–‡ä»¶æ›´æ–°
        file_mtime = os.path.getmtime(output_path)
        mtime_str = datetime.fromtimestamp(file_mtime).strftime('%H:%M:%S')
        print(f"âœ… JSONä¿å­˜æˆåŠŸï¼ä¿®æ”¹æ—¶é—´ï¼š{mtime_str}")
        print(f"ğŸ“„ æ–‡ä»¶è·¯å¾„ï¼š{output_path}")
    except Exception as e:
        raise Exception(f"ä¿å­˜JSONå¤±è´¥ï¼š{str(e)}")


def print_sample_data(data: Dict) -> None:
    print("\nğŸ“Œ æœ¬æ¬¡æ›´æ–°ï¼š")
    print(f"  å…¨å±€æ›´æ–°æ—¶é—´ï¼š{data['globalUpdateTime']}")
    print(f"  ç„¦ç‚¹è¯æï¼š{data['focusHerb']['name']} | æ›´æ–°æ—¶é—´ï¼š{data['focusHerb']['updateTime']}")
    print("-" * 50)


# ===================== æ‰§è¡Œé€»è¾‘ï¼ˆé€‚é…tuijian-endç›®å½•ï¼‰ =====================
def run_script_once(excel_path: str, output_path: str, max_count: int = 10) -> None:
    """å•æ¬¡æ‰§è¡Œï¼ˆå¼ºåˆ¶æ›´æ–°JSONï¼‰"""
    try:
        print(f"\n{'=' * 60}")
        print(f"â±ï¸  æ‰§è¡Œæ—¶é—´ï¼š{datetime.now().strftime('%H:%M:%S')}")
        print(f"{'=' * 60}")

        df = load_excel_data(excel_path)
        df_core = clean_duplicate_data(df, max_count)
        herb_data = generate_herb_info(df_core)
        save_to_json(herb_data, output_path)

        print_sample_data(herb_data)
        print(f"ğŸ‰ æ‰§è¡Œå®Œæˆï¼")

    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")


def run_script_demo_mode(excel_path: str, output_path: str, interval_seconds: int = 30, max_count: int = 10) -> None:
    """æ¼”ç¤ºæ¨¡å¼ï¼š30ç§’è‡ªåŠ¨æ›´æ–°JSON"""
    print("ğŸš€ æ¼”ç¤ºæ¨¡å¼å¯åŠ¨ï¼ï¼ˆè„šæœ¬ä½äºtuijian-endç›®å½•ï¼‰")
    print(f"ğŸ”„ é—´éš”ï¼š{interval_seconds}ç§’ | æŒ‰Ctrl+Cåœæ­¢")
    print(f"ğŸ“„ Excelï¼š{excel_path}")
    print(f"ğŸ“¤ JSONï¼š{output_path}")
    print("=" * 60)

    # é¦–æ¬¡æ‰§è¡Œ
    run_script_once(excel_path, output_path, max_count)

    # å¾ªç¯æ‰§è¡Œ
    execute_count = 1
    while True:
        try:
            # å€’è®¡æ—¶æç¤º
            for i in range(interval_seconds, 0, -1):
                print(f"\râŒ› ä¸‹æ¬¡æ‰§è¡Œå€’è®¡æ—¶ï¼š{i}ç§’", end="", flush=True)
                time.sleep(1)

            # å¼ºåˆ¶æ‰§è¡Œæ›´æ–°
            execute_count += 1
            print(f"\n\nã€ç¬¬{execute_count}æ¬¡æ‰§è¡Œã€‘")
            run_script_once(excel_path, output_path, max_count)

        except KeyboardInterrupt:
            print(f"\n\nğŸ›‘ æ¼”ç¤ºåœæ­¢ï¼ç´¯è®¡æ‰§è¡Œ{execute_count}æ¬¡")
            break
        except Exception as e:
            print(f"\nâš ï¸  å¼‚å¸¸ï¼Œ{interval_seconds}ç§’åé‡è¯•ï¼š{str(e)}")
            time.sleep(interval_seconds)


# ===================== ä¸»å‡½æ•°ï¼ˆæ ¸å¿ƒï¼šä¿®æ”¹JSONè¾“å‡ºåˆ°frontend/src/viewsï¼‰ =====================
if __name__ == "__main__":
    # 1. è·¯å¾„è®¡ç®—ï¼ˆé€‚é…æ–°çš„JSONè¾“å‡ºç›®å½•ï¼šfrontend/src/viewsï¼‰
    script_dir = Path(__file__).parent  # å½“å‰ç›®å½• = tuijian-end
    team_test_dir = script_dir.parent  # ä¸Šçº§ç›®å½• = team-test

    # Excelè·¯å¾„ä¸å˜ï¼ˆä»åœ¨team-test/tuijian-endä¸‹ï¼‰
    EXCEL_FILE_PATH = team_test_dir / "./tuijian-end/medicines_details_converted.xlsx"
    # JSONè¾“å‡ºè·¯å¾„æ”¹ä¸ºï¼šteam-test/frontend/src/complete_herb_data.json
    OUTPUT_JSON_PATH = team_test_dir / "./frontend/src/complete_herb_data.json"

    # 2. é…ç½®å‚æ•°
    MAX_HERB_COUNT = 100  # æ¯æ¬¡ç”Ÿæˆçš„è¯ææ•°é‡
    DEMO_INTERVAL_SECONDS = 30  # è‡ªåŠ¨æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰

    # æ‰“å°è·¯å¾„éªŒè¯ï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
    print(f"ğŸ“Œ è„šæœ¬æ‰€åœ¨ç›®å½•ï¼š{script_dir.absolute()}")
    print(f"ğŸ“Œ Excelè·¯å¾„ï¼ˆç»å¯¹ï¼‰ï¼š{EXCEL_FILE_PATH.absolute()}")
    print(f"ğŸ“Œ JSONè¾“å‡ºè·¯å¾„ï¼š{OUTPUT_JSON_PATH.absolute()}")

    # å¯åŠ¨æ¼”ç¤ºï¼ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²è·¯å¾„ï¼Œå…¼å®¹osæ¨¡å—ï¼‰
    run_script_demo_mode(
        excel_path=str(EXCEL_FILE_PATH),
        output_path=str(OUTPUT_JSON_PATH),
        interval_seconds=DEMO_INTERVAL_SECONDS,
        max_count=MAX_HERB_COUNT
    )